**SignDine** is an AI-powered restaurant ordering system that uses computer vision and deep learning to recognize sign language gestures and convert them into menu selections. The goal is to enable seamless and independent dining experiences for individuals with speech and hearing impairments.

---
## Features

- Real-time sign language detection via webcam.
- Gesture classification mapped to food menu items.
- Order confirmation and display interface.
- Scalable architecture for adding new gestures.
- Smooth integration with restaurant ordering systems.

---

## Tech Stack

- **Programming Language**: Python  
- **Computer Vision**: OpenCV  
- **Deep Learning**: TensorFlow / Keras  
- **UI**: Streamlit (or Tkinter / Flask depending on your implementation)  
- **Data Preparation & Annotation**: MediaPipe / Custom datasets  
- **Model Type**: CNN (Convolutional Neural Network)
